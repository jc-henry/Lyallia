---
title: "pipeline_Lyallia"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Check Illumina read quality with FastQC v0.11.9
```{console}
$ fastqc -f 'List of raw Illumina read files'
```

Run Rcorrector v1.0.4 to correct erroneous kmers for Illumina reads
```{console}
$ run_rcorrector.pl -1 'Forward reads' -2 'Reverse reads' -k 23
```

Use the the Harvard Informatics GitHub repo TranscriptomeAssemblyTools script to filter Rcorrected reads and fix headers (requires Python 2.7)
```{console}
$ python FilterUncorrectabledPEfastq.py -1 'Forward reads' -2 'Reverse reads'
```

Run TrimGalore! v0.6.4 to remove adapter contamination and poor quality bases (Using the default Phred quality score of 20)
```{console}
$ trim_galore --length 50 --paired --basename 'Population_n' --retain_unpaired --gzip 'Forward reads' 'Reverse reads'
```

Recheck Illumina read quality with FastQC v0.11.9 after quality processing
```{console}
$ fastqc -f 'List of filtered Illumina read files'
```

Generate CCS reads from PacBio subreads (using SMRT Link v8.0.0)
```{console}
$ ccs --num-threads 48 --min-rq 0.99 --report-file ./pacbio_ccs_lyallia_report.txt --log-file pacbio/pacbio_ccs_lyallia_log.txt  subreads.bam lyallia_ccs.bam
```

CCS read orientation and primer removal. Sequences in primers.fasta file:
>primer_5p
AAGCAGTGGTATCAACGCAGAGTACATGGGG
>primer_3p
GTACTCTGCGTTGATACCACTGCTT

```{console}
$ lima --isoseq --num-threads 12 --dump-clips lyallia_ccs.bam primers.fasta lima.bam
```

PolyA tail trimming and concatemer removal
```{console}
$ isoseq3 refine --num-threads 12 --require-polya lima.primer_5p--primer_3p.bam primers.fasta
```

Clustering to generate FLNC reads
```{console}
$ isoseq3 cluster --num-threads 12 flnc.bam cluster.bam --verbose --use-qvs
```

Headers of the high-quality FLNC reads need to be tidied up for downstream analyses (change slashes to underscores)
```{console}
$ sed 's/\//_/g' cluster.hq.fasta > clean_header_hq.fasta
```

Make Trinity v2.11.0 de novo assembly
```{console}
$ Trinity --CPU 10 --max_memory 170G --seqType fq --left AUS30_0_R1_val_1.fq.gz,AUS30_2_R1_val_1.fq.gz,AUS30_3_R1_val_1.fq.gz --right AUS30_0_R2_val_2.fq.gz,AUS30_2_R2_val_2.fq.gz,AUS30_3_R2_val_2.fq.gz --min_contig_length 300 --include_supertranscripts 
```

Quantify the Trinity Transcripts with Salmon v1.5.1. Need to create the index first
```{console}
$ salmon index --index Trinity_index --transcripts Trinity.fasta -k 31
$ salmon quant --index Trinity_index --libType IU -1 'Input AUS30 forward reads' -2 'Input AUS30 reverse reads' -p 6 --validateMappings --gcBias 
```

Make a file with TPM values for all 3 samples
Taking just the transcript IDs and TPM values from each quant file
```{console}
$ cut -f1,4 AUS30_0_quant.sf | tail -n +2 > aus30_0_TPM.txt
$ cut -f1,4 AUS30_2_quant.sf | tail -n +2 > aus30_2_TPM.txt
$ cut -f1,4 AUS30_3_quant.sf | tail -n +2 > aus30_3_TPM.txt
$ paste aus30_0_TPM.txt aus30_2_TPM.txt aus30_3_TPM.txt > Trinity_TPM.txt
cut -f1,2,4,6 Trinity_TPM.txt > Trinity_clean_TPM.txt
```

Use the Trinity filter_low_expr_transcripts.pl script to extract the transcript with the highest read support from each Trinity cluster
```{console}
$ filter_low_expr_transcripts.pl --matrix Trinity_clean_TPM.txt --transcripts Trinity.fasta --highest_iso_only --trinity_mode > high_expression_contigs.fasta
```

Get basic assembly stats for the PacBio and Trinity transcripts
```{console}
$ TrinityStats.pl 'input fasta' > stats.txt
```

Run BUSCO v5.2.2 to check transcriptome completeness for the PacBio and Trinity transcripts
```{console}
$ busco --in 'input fasta' --cpu 1 --out --mode transcriptome  --lineage_dataset eudicots_odb10 --force --quiet
```

Run TransDecoder v5.5.0 to find predicted proteins. Runs in two steps
```{console}
$ TransDecoder.LongOrfs -t 'input fasta' -m 100 --output_dir ./

$ TransDecoder.Predict -t 'input fasta' --single_best_only --output_dir ./
```

BLAST v2.10.0 search the PacBio and Trinity transcripts against A. thaliana proteins. Need to create the BLAST database first
```{console}
$ makeblastdb -in ./Araport11_genes.pep.fasta -out ./Araport11_genes.pep -dbtype prot

$ blastx -query 'input fasta' -db Araport11_genes.pep -out blastx.outfmt6 evalue 1e-5 -max_target_seqs 1 -max_hsps 1 -outfmt 6
```

CD-HIT-EST v4.8.1 to cluster redundant FLNC transcripts
```{console}
$ cd-hit-est -i clean_header_hq.fasta -o pacbio_cdhit.fasta -c 0.99 -n 10 -aL 0.99 -T 24
```


Quality of the filtered PacBio transcriptome now assessed using TrinityStats.pl, BUSCO, Transdecoder, and Blastx using the same parameters as used previously.


Transcript quantification with Salmon v1.5.1. Need to create the index first
```{console}
$ salmon index --index index_pacbio_cdhit --pacbio_cdhit.fasta -k 31
$ salmon quant --index ./index_pacbio_cdhit --libType IU -1 'input Illumina forward reads' -2 'input Illumina reverse reads' -p 6 --validateMappings --gcBias 
```

Sum expression data to A. thaliana gene level and output files as expression data matrices
```{console}
# See the collapse_gene.R script
```

Perform PCA on all genes in which at one population is significantly differentially expressed
```{console}
# See the araport_gene_PCA.Rmd file
```

Need to make a tx2gene mapping file for performing DE at the A. thaliana gene level. Using the BLASTx results
```{console}
# See the make_tx2gene.R file
```

Perform all six DESeq2 v1.30.1 comparisons between the AUS and PCR populations
```{console}
# See the DESeq2_aus25_vs_pcr1.Rmd example file
```

Get intersections of DEGS and create an UpSet plot (UpSetR v1.4.0) to visualise DEGs
```{console}
# See the upset.R file
```

Make a list of A. thaliana genes for GO term annotation
```{console}
# See the araport_gene_background_for_GO.R file
```

Need to reformat the A. thaliana gene - GO term list for use with AgriGO v2
```{console}
# See the go_background.R file
```

Annotate the DEGs from DESeq2 with GO terms
```{console}
# See the go_annotations.R example file
```


Upload the lists of variously upregulated and downregulated genes to AgriGOv2. After SEA analyses (minimum mapping entries = 5, p < 0.05, no correction for multiple testing), save the output files and charts of enriched GO terms.


Use venn v1.10 to find overlapping GO terms and ggvenn v0.1.9 to construct venn diagrams
```{console}
# See the venn_GO_upreg.R and venn_GO_downreg.R files
```

Append full GO term descriptions to the venn intersections
```{console}
# See the bind_GO_titles.R file
```

Make a list of transcripts (representing each A. thaliana gene) for use in iTAK
```{console}
# See the genes_itak.R file
```

Use seqtk v1.3 to subset the FLNC reads so only the representative sequences remain. Need to also remove unnecessary info from the fasta headers for later pattern matching (take off everything after and including the first space)
```{console}
$ seqtk subseq pacbio_cdhit.fasta transcripts_from_araport_mapping_nonredundant.txt > nonredundant_gene.fasta
$ sed '/^>/s/ .*//' nonredundant_gene.fasta > trimmed_header_nonredundant_gene.fasta
```

Use the phylotools v0.2.2 package to generate a fasta of all nonredundant (according to Araport gene ID) transcripts with araport gene IDs
```{console}
# See the rename_fasta.R file
```

For each list of up and downregulated genes, seqtk was used to create a fasta with only those genes. For example:
```{console}
$ seqtk subseq araport_name_cdhit.fasta upreg_geneIDonly_aus25_pcr1_padj0.5_1.5fc.txt > aus25_pcr1_upreg.fasta
```

iTAK was run on each of the above output files. For example:
```{console}
$ perl iTAK.pl aus25_pcr1_upreg.fasta
```